# importing kaggle library 
!pip install kaggle

#from kaggle.api.kaggle_api_extended import KaggleApi

import os 
from kaggle.api.kaggle_api_extended import KaggleApi 
# Change to the directory where you want to save the dataset 
os.chdir('/lakehouse/default/Files') 

# Set Kaggle API credentials 
os.environ['KAGGLE_USERNAME'] = 'sibahlehashe' 
os.environ['KAGGLE_KEY'] = 'cfa73cdfdcd56065e4f0d2f8a295cedb' 
# Authenticate with Kaggle API 
api = KaggleApi() 
api.authenticate() 
# Download the dataset 
api.dataset_download_file(dataset='sibahlehashe/kaggle', file_name='Restaurant-revenue(1).csv', path='/lakehouse/default/Files')

or
import os 
os.chdir('/lakehouse/default/Files') 
os.environ['KAGGLE_USERNAME'] = 'olacharles' 
os.environ['KAGGLE_KEY'] = 'e500dc327936878e4727f156b0840f24' 
from kaggle.api.kaggle_api_extended import KaggleApi 
api = KaggleApi() 
api.authenticate() 
api.dataset_download_file('mrsimple07/restaurants-revenue-prediction', 'Restaurant_revenue(1).csv')


#identify path
path = "abfss://bdf9608b-9ebc-4742-ba14-b9eff415e693@onelake.dfs.fabric.microsoft.com/75df1207-415d-4262-b704-d40a682f70e4/Files/Restaurant_revenue (1).csv" 


#creating DF
df = spark.read.csv(path, header=True, inferSchema=True)

#creating dimension table
Dimension_df = df.select('Cuisine_Type')

Dimension_df.show()

#Dropping duplicates from Dimension_df
Dimension_df = Dimension_df.dropDuplicates()

#checking type 
type(Dimension_df)

#Converting to Pandas dataframe
Dimension_dataframe = Dimension_df.toPandas()

#converting to pandas from sprak df
df =  df.toPandas()

#resetting index
Dimension_dataframe.reset_index(drop=True,inplace=True)

#creating new column "Cusinetype" - values are the lenth of rows
Dimension_dataframe['CuisineTypeID'] = range(0,0+len(Dimension_dataframe))

#Creating full table

full_table = df.merge(Dimension_dataframe, on = 'Cuisine_Type', how='left')

# Code generated by Data Wrangler for pandas DataFrame
def clean_data(fact_table):
    # Drop column: 'Cuisine_Type' because it is a dimension table,'CuisineTypeID' with reference the table
    fact_table = fact_table.drop(columns=['Cuisine_Type'])
    return fact_table
fact_table_clean = clean_data(fact_table.copy())
fact_table_clean.head()

# Code generated by Data Wrangler for pandas DataFrame to create anotehr dimension table 
def clean_data(fact_table_clean):
    # Drop columns: 'Number_of_Customers', 'Menu_Price' and 5 other columns
    fact_table_clean = fact_table_clean.drop(columns=['Number_of_Customers', 'Menu_Price', 'Marketing_Spend', 'Average_Customer_Spending', 'Reviews', 'Monthly_Revenue', 'CuisineTypeID'])
    # Drop duplicate rows across all columns
    fact_table_clean = fact_table_clean.drop_duplicates()
    return fact_table_clean
promo_table = clean_data(fact_table_clean.copy())
promo_table.head()

#Mapping column to value 0=No & 1=Yes. Creating column PromotionName
promo_table['PromotionName'] = promo_table['Promotions'].map({0:'No',1:'Yes'})
promo_table.head()

#Converting fact_table_clean df into spark df
spark_fact_table = spark.createDataFrame(fact_table_clean)

#Changing pandas dataframes to spark dataframe
spark_Dimension_dataframe = spark.createDataFrame(Dimension_dataframe)
spark_promo_dataframe = spark.createDataFrame(promo_table)

#saving as table fact_Resturant
spark_fact_table.write.format("delta").mode("overwrite").saveAsTable("fact_Resturant")

#saving as table DimPromotions & Cusine_table
spark_promo_dataframe.write.format("delta").mode("overwrite").saveAsTable("DimPromotions")
spark_Dimension_dataframe.write.format("delta").mode("overwrite").saveAsTable("Cusine_table")

df.write.format('delta').mode('Overwrite').saveAsTable("Raw_table")


